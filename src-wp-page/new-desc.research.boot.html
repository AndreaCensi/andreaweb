<section class='research-topic'>
<h3>3. Sensorimotor Learning and Bootstrapping</h3>

<p>
    Imagine you are a brain-in-a-vat that wakes up connected to 
    an unknown body through two streams of uninterpreted observationd and commands, 
    without any prior knowledge of the sensors, actuators or environment.
    Would you be able to learn a model of your body and use it to perform useful tasks?
    This is the "bootstrapping scenario": the learning problem for an embodied
    agent in the limit of prior knowledge tending to zero.
</p>

<div style='width: 320px; margin-left: 10em'>
    <div>
    <object width="320" height="148"><param name="allowfullscreen" value="true" /><param name="allowscriptaccess" value="always" /><param name="movie" value="http://vimeo.com/moogaloop.swf?clip_id=19263374&amp;server=vimeo.com&amp;show_title=0&amp;show_byline=0&amp;show_portrait=0&amp;color=00ADEF&amp;fullscreen=1&amp;autoplay=1&amp;loop=1" /><embed src="http://vimeo.com/moogaloop.swf?clip_id=19263374&amp;server=vimeo.com&amp;show_title=0&amp;show_byline=0&amp;show_portrait=0&amp;color=00ADEF&amp;fullscreen=1&amp;autoplay=1&amp;loop=1" type="application/x-shockwave-flash" allowfullscreen="true" allowscriptaccess="always" width="320" height="148"></embed></object> 
    </div>
    <p style="font-style: italic; font-size: smaller">
    Uninterpreted streams of observations and commands from a robotic sensorimotor cascade.
    </p>
</div>


<!-- <p>
  There is considerable evidence that brains are able 
</p>


<p>
Other than a worthy problem per se (it subsumes most problems of learning, calibration, fault detection, etc.), it is also a proxy for studying some aspects of the higher level of neural processing. In fact, it is believed that the cortex starts as a *tabula rasa* that adapts to the inputs (the evidence is that parts of it can be repurposed in subjects that lost some sensory capacity).
</p>
 -->
<!-- 	<p>Learning and adaptivity are useful for designing complex systems.</p>

  <p>By "Sensorimotor learning", we mean learning models that represent sensorimotor knowledge, that
  can interpret raw data coming from signals and actuators.

 -->	
 <p>My research in this field is guided by the questions:</p>
    <ul>
      <li><em>Theory</em>: How much prior knowledge is needed by an agent? </li>
      <li><em>Algorithmics</em>: What are tractable classes of models for sensorimotor learning? </li>
      <li><em>Systems</em>: How can we introduced learning and adaptivity functionality in traditional robotic control systems?</li>
    </ul>


<!-- 
<p>
At this point, it is not clear if an agent can learn everything from the environment, or if there is something that should be known a priori. My goal has been to try to derive some precise formulation of the problem, and to find strong results (in the spirit of control theory) that can be built upon.
</p>
 -->
<!--
Representative papers:

- [Bootstrapping, uncertain semantics, and invariance (PDF)][semantics]   (preprint)
- [A group-theoretic approach to formalizing bootstrapping problems (PDF)][bgds_tr]  (preprint)
- [Bootstrapping bilinear models of sensorimotor cascades][bds] (ICRA'11)
-->
<!-- 
[bgds_tr]: http://purl.org/censi/2011/bgds_tr
[semantics]: http://purl.org/censi/research/2011-icdl-invariance.pdf
[dissertation]: http://purl.org/censi/2012/phd

[bevideos]: http://purl.org/censi/research/2011-bgds/
[bevideos_old]: http://purl.org/censi/2010/be
[bds]: http://purl.org/censi/2010/boot
[many other videos]: bevideos
 -->
<div style='clear: both'>&nbsp;</div>


<div class='video-gallery-int'>
  
  <div class='video'>
    <iframe src="http://player.vimeo.com/video/129613732" 
    width="240" height="135" 
    frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
    <p style="width: 240px">A recent talk (May 2015) about my learning work.</p>
  </div>

  <div class='video'>
      <iframe src="http://player.vimeo.com/video/80954603" width="240" height="135"   
      frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
      <p style="width: 240px">Bootstrapping Vehicles (<a href="http://www.vimeo.com/80954603">full screen</a>; <a href="http://purl.org/censi/2013/jbds">paper</a>)</p>
  </div>

  <div class='video'>
    <iframe src="http://player.vimeo.com/video/65564176" width="240" height="135"   frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
    <p style="width: 240px">Planning with learned diffeomorphisms (<a href="http://www.vimeo.com/65564176">full screen</a>; 
      <a href="http://purl.org/censi/2012/dptr1">paper</a>)</p>
  </div>

</div>

<div style="width: 65em">

<div style='float: right; margin: 1em; margin-right: 3em; clear: right; width: 25em'>
    <div>
    <object width="320" height="220"><param name="allowfullscreen" value="true" /><param name="allowscriptaccess" value="always" /><param name="movie" value="http://vimeo.com/moogaloop.swf?clip_id=19271333&amp;server=vimeo.com&amp;show_title=0&amp;show_byline=0&amp;show_portrait=0&amp;color=00ADEF&amp;fullscreen=1&amp;autoplay=1&amp;loop=1" /><embed src="http://vimeo.com/moogaloop.swf?clip_id=19271333&amp;server=vimeo.com&amp;show_title=0&amp;show_byline=0&amp;show_portrait=0&amp;color=00ADEF&amp;fullscreen=1&amp;autoplay=1&amp;loop=1" type="application/x-shockwave-flash" allowfullscreen="true" allowscriptaccess="always" width="320" height="220"></embed></object> 
    </div>
    <p style="width: 320px; font-style: italic; font-size: smaller">
     The video shows learning of a bilinear model of a sensorimotor cascade for a camera. The agent starts with no previous knowledge on the sensor geometry, and by correlating observations with commands, it can learn a generative model for the data. The same model can be used for learning the dynamics of different sensors (range-finder, camera, field sampler).
    See <a href="http://purl.org/censi/research/2011-bgds/">many other videos</a> of related experiments.
    </p>
</div>
<div style='float: left; margin-top: 2em'>
<p class="recent-papers">Representative works: </p>
[pub_ref_compact id='censi13jbds_sub']
[pub_ref_compact id='censi12cameracalib']
[pub_ref_compact id='censi13motion']
[pub_ref_compact id='censi12diffeo'] 
[pub_ref_compact id='censi11semantics']
[pub_ref_compact id='censi13joint']

<p>My dissertation:</p>

[pub_ref_compact id='censi12phd']

</div>
</div>

<p class=recent-workshops style='clear: both'>Recent workshop: 
<ul><li><a href="http://sensorimotor-learning.mit.edu/">ICRA 2015 workshop on Advances in Sensorimotor Learning</a></li></ul></p>
   
</section>