<section class='research-topic'>

<h3>2. Co-design of sensing, computation, and actuation</h3>

<p> I'm interested in co-design problems that couple sensing, computation, and actuation in a non-trivial way, especially from the point of view
of design minimality and resource-performance trade-offs.
</p>

<p>
In particular, I'm interested in the robotics applications 
of event-basde <strong>neuromorphic sensors</strong>. Neuromorphic sensors are a new kind of sensor with impressive capabilities: their output is a stream of events, generated every time there is a change in the local brightness perceived by a pixel. </p>

<div style='width: 30em; margin-left: 4em; margin-top: 1em; margin-bottom: 1em '>

<img style="width: 30%; border: solid 1px black;" src="https://github.com/AndreaCensi/env_dvs/blob/master/l2.aedat.show_simple-0.03.gif?raw=true"/>

<img style="width: 30%; border: solid 1px black" src="https://github.com/AndreaCensi/env_dvs/blob/master/l2.aedat.show_simple-0.001.gif?raw=true"/>

<img  style="width: 30%; margin-left: 0; border: solid 1px black;" src="http://purl.org/censi/research/2013-dvsd/events.gif"/>

<p style="font-size: smaller; font-family: italic">Events from a neuromorphic sensor, in real time (left) and slowed down 50x (center). On the right, events
superimposed with a CMOS sensor's output. </p>

</div>



  <p>My research is guided by the questions:</p>
    <ul>

      <li><em>Theory:</em> 

          How can we formally say that this sensor class is better than another? For what tasks? In what environments?

      </li>

      <li><em>Algorithms:</em> 

          How can we obtain "zero-latency" event-based controllers?

      </li>

      <li><em>Systems:</em> 

          How can we integrate these sensors in existing control architectures?
      </li>

    </ul>

    
<div>
[pub_ref_compact id='censi15powerperf_sub']

[pub_ref_compact id='fuller14controlling']

[pub_ref_compact id='censi13dvsd_sub']

[pub_ref_compact id='censi13saccade']

[pub_ref_compact id='censi13dvs']
</div>
    
	<p class=recent-workshops>Recent workshops:</p>
  <ul>  
	    <li> <a href="http://innovative-sensing.mit.edu/">ICRA 2015 workshop on Innovative Sensing in Robotics</a></li>
      <li> <a href="http://www-users.cs.umn.edu/~isler/workshop/active-perception/">
      ICRA 2015 workshop on Scaling Up Active Perception</a></li>
  </ul>
 
<div class='video-gallery-int'>
  <div class='video'>
      <iframe src="http://player.vimeo.com/video/98832025" width="240" height="135" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
      <p style="width: 240px">The robot fly was blind but now it sees! (<a href="http://www.vimeo.com/98832025">full screen</a>; <a href="http://rsif.royalsocietypublishing.org/content/11/97/20140281">paper</a>)</p>
  </div>

  <div class='video'>
  <iframe src="http://player.vimeo.com/video/19194748" width="160" height="135"   frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
  <p style="width: 240px">A fruit fly's perspective on the world (<a href="http://www.vimeo.com/19194748">full screen</a>; 
    <a href="http://purl.org/censi/2011/saccade">paper</a>)</p>
  </div>
</div>
</section>